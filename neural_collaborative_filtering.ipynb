{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In [Lesson 5](http://course.fast.ai/lessons/lesson5.html) of Fast.ai course, Jeremy Howard mentions about using neural networks for collaborative filtering. The course implements this using PyTorch and Fast.ai library. I have tried to implement the same using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommender Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommender systems are all around us. From Amazon to Google to Netflix, everyone is trying to use recommender systems to recommend what products to buy next or what movies to watch.  \n",
    "Below are some of the statistics which will help in determining the importance of these systems.  \n",
    "* **Netflix**: 2/3 movies watched are recommended  \n",
    "* **Google News**: recommendations generate 38% more clickthrough  \n",
    "* **Amazon**: 35% sales from recommendations  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the newer, narrower sense, collaborative filtering is a method of making automatic predictions (filtering) about the interests of a user by collecting preferences or taste information from many users (collaborating). The underlying assumption of the collaborative filtering approach is that if a person A has the same opinion as a person B on an issue, A is more likely to have B's opinion on a different issue than that of a randomly chosen person.  \n",
    "The traditional approach of CF uses matrix factorization to learn the attitudes and preferences of users and create a small latent space which will capture all the information. These are called **Embeddings**.  \n",
    "Let us use deep learning to learn these embedding matrices instead of the traditional matrix factorization methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the new MovieLens Dataset that has approximately 100000 ratings, 9000 movie and 700 users Available here: [https://grouplens.org/datasets/movielens/](https://grouplens.org/datasets/movielens/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Embedding, Reshape, Activation, Input, Dense, Flatten, Dropout\n",
    "from keras.layers.merge import Dot, multiply, concatenate\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import merge, Merge\n",
    "from keras.optimizers import Adagrad, Adam, SGD, RMSprop\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('ml-latest-small/ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1260759144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1029</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1061</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1129</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1172</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1260759205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1       31     2.5  1260759144\n",
       "1       1     1029     3.0  1260759179\n",
       "2       1     1061     3.0  1260759182\n",
       "3       1     1129     2.0  1260759185\n",
       "4       1     1172     4.0  1260759205"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100004, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users 671\n",
      "Number of unique movies 9066\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique users ' + str(len(data.userId.unique())))\n",
    "print('Number of unique movies ' + str(len(data.movieId.unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign a unique number between 0 and # users to each user. Do the same for movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.userId = data.userId.astype('category').cat.codes.values\n",
    "data.movieId = data.movieId.astype('category').cat.codes.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1260759144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>833</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>859</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>906</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>931</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1260759205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       0       30     2.5  1260759144\n",
       "1       0      833     3.0  1260759179\n",
       "2       0      859     3.0  1260759182\n",
       "3       0      906     2.0  1260759185\n",
       "4       0      931     4.0  1260759205"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users 671\n",
      "Number of unique movies 9066\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique users ' + str(len(data.userId.unique())))\n",
    "print('Number of unique movies ' + str(len(data.movieId.unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data set into train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model is a simple linear model where we learn a dense representation of each movies and users in our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_embedddings = 30\n",
    "num_movies = len(data.movieId.unique())\n",
    "num_users = len(data.userId.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_inputs = Input(shape=(1,), dtype='int32')\n",
    "m = Embedding(num_movies + 1, dim_embedddings, name=\"movie\")(m_inputs)\n",
    "\n",
    "u_inputs = Input(shape=(1,), dtype='int32')\n",
    "u = Embedding(num_users + 1, dim_embedddings, name=\"user\")(u_inputs)\n",
    "\n",
    "o = multiply([m, u])\n",
    "o = Dropout(0.5)(o)\n",
    "o = Flatten()(o)\n",
    "o = Dense(1)(o)\n",
    "\n",
    "rec_model = Model(inputs=[m_inputs, u_inputs], outputs=o)\n",
    "rec_model.compile(loss='mae', optimizer='adam', metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 72002 samples, validate on 8001 samples\n",
      "Epoch 1/5\n",
      " - 28s - loss: 2.2587 - mean_absolute_error: 2.2587 - val_loss: 0.9891 - val_mean_absolute_error: 0.9891\n",
      "Epoch 2/5\n",
      " - 10s - loss: 0.8437 - mean_absolute_error: 0.8437 - val_loss: 0.7412 - val_mean_absolute_error: 0.7412\n",
      "Epoch 3/5\n",
      " - 10s - loss: 0.7211 - mean_absolute_error: 0.7211 - val_loss: 0.7190 - val_mean_absolute_error: 0.7190\n",
      "Epoch 4/5\n",
      " - 10s - loss: 0.6803 - mean_absolute_error: 0.6803 - val_loss: 0.7172 - val_mean_absolute_error: 0.7172\n",
      "Epoch 5/5\n",
      " - 10s - loss: 0.6524 - mean_absolute_error: 0.6524 - val_loss: 0.7160 - val_mean_absolute_error: 0.7160\n"
     ]
    }
   ],
   "source": [
    "history = rec_model.fit([train.movieId, train.userId], train.rating, epochs=5, verbose=2, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.70013000026869\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(test.rating, rec_model.predict([test.movieId, test.userId])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this model we introduce a bias. The first model does not explicitly take into account the bias that a user might have in giving consistently high scores to every movie he watches or a movie having consistently bad scores for all users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = 1\n",
    "m_inputs = Input(shape=(1,), dtype='int32')\n",
    "m = Embedding(num_movies + 1, dim_embedddings, name=\"movie\")(m_inputs)\n",
    "m_bias = Embedding(num_movies + 1, bias, name=\"moviebias\")(m_inputs)\n",
    "\n",
    "u_inputs = Input(shape=(1,), dtype='int32')\n",
    "u = Embedding(num_users + 1, dim_embedddings, name=\"user\")(u_inputs)\n",
    "u_bias = Embedding(num_users + 1, bias, name=\"userbias\")(u_inputs)\n",
    "\n",
    "o = multiply([m, u])\n",
    "o = concatenate([o, m_bias, u_bias])\n",
    "o = Dropout(0.5)(o)\n",
    "o = Flatten()(o)\n",
    "o = Dense(1)(o)\n",
    "\n",
    "rec_model = Model(inputs=[m_inputs, u_inputs], outputs=o)\n",
    "rec_model.compile(loss='mae', optimizer='adam', metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 72002 samples, validate on 8001 samples\n",
      "Epoch 1/5\n",
      " - 12s - loss: 2.0693 - mean_absolute_error: 2.0693 - val_loss: 0.9141 - val_mean_absolute_error: 0.9141\n",
      "Epoch 2/5\n",
      " - 11s - loss: 0.9005 - mean_absolute_error: 0.9005 - val_loss: 0.7349 - val_mean_absolute_error: 0.7349\n",
      "Epoch 3/5\n",
      " - 11s - loss: 0.7172 - mean_absolute_error: 0.7172 - val_loss: 0.7117 - val_mean_absolute_error: 0.7117\n",
      "Epoch 4/5\n",
      " - 11s - loss: 0.6581 - mean_absolute_error: 0.6581 - val_loss: 0.7104 - val_mean_absolute_error: 0.7104\n",
      "Epoch 5/5\n",
      " - 13s - loss: 0.6223 - mean_absolute_error: 0.6223 - val_loss: 0.7100 - val_mean_absolute_error: 0.7100\n"
     ]
    }
   ],
   "source": [
    "history = rec_model.fit([train.movieId, train.userId], train.rating, epochs=5, verbose=2, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6915087548263502\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(test.rating, rec_model.predict([test.movieId, test.userId])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a deeper model. This model is an implementation of this [Neural Collaborative Filtering](https://arxiv.org/abs/1708.05031) paper, code for which can be found at this github [link](https://github.com/hexiangnan/neural_collaborative_filtering).  \n",
    "I would recommend reading the paper and going through the code to gain a deeper understanding of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_dim = 8\n",
    "layers = [64, 32, 16, 8]\n",
    "user_input = Input(shape=(1,), dtype='int32', name = 'user_input')\n",
    "movie_input = Input(shape=(1,), dtype='int32', name = 'movie_input')\n",
    "\n",
    "MF_Embedding_User = Embedding(input_dim = num_users + 1, output_dim = mf_dim, name = 'mf_embedding_user', input_length=1)\n",
    "MF_Embedding_Movie = Embedding(input_dim = num_movies + 1, output_dim = mf_dim, name = 'mf_embedding_movie', input_length=1)\n",
    "\n",
    "MLP_Embedding_User = Embedding(input_dim = num_users + 1, output_dim = int(layers[0]/2), name = \"mlp_embedding_user\", input_length=1)\n",
    "MLP_Embedding_Movie = Embedding(input_dim = num_movies + 1, output_dim = int(layers[0]/2), name = 'mlp_embedding_movie', input_length=1)\n",
    "\n",
    "mf_user_latent = Flatten()(MF_Embedding_User(user_input))\n",
    "mf_movie_latent = Flatten()(MF_Embedding_Movie(movie_input))\n",
    "\n",
    "mf_vector = merge([mf_user_latent, mf_movie_latent], mode = 'mul')\n",
    "\n",
    "mlp_user_latent = Flatten()(MLP_Embedding_User(user_input)) \n",
    "mlp_movie_latent = Flatten()(MLP_Embedding_Movie(movie_input))\n",
    "\n",
    "mlp_vector = merge([mlp_user_latent, mlp_movie_latent], mode = 'concat')\n",
    "\n",
    "for idx in range(1, len(layers)):\n",
    "    layer = Dense(layers[idx], activation='relu', name=\"layer%d\" %idx)\n",
    "    mlp_vector = layer(mlp_vector)\n",
    "                  \n",
    "predict_vector = merge([mf_vector, mlp_vector], mode = 'concat')\n",
    "prediction = Dense(1, activation='sigmoid', init='lecun_uniform', name = \"prediction\")(predict_vector)\n",
    "\n",
    "model = Model(input=[user_input, movie_input], output=prediction)\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_input (InputLayer)         (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "movie_input (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mlp_embedding_user (Embedding)  (None, 1, 32)        21504       user_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mlp_embedding_movie (Embedding) (None, 1, 32)        290144      movie_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 32)           0           mlp_embedding_user[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 32)           0           mlp_embedding_movie[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "merge_2 (Merge)                 (None, 64)           0           flatten_5[0][0]                  \n",
      "                                                                 flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "mf_embedding_user (Embedding)   (None, 1, 8)         5376        user_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mf_embedding_movie (Embedding)  (None, 1, 8)         72536       movie_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "layer1 (Dense)                  (None, 32)           2080        merge_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 8)            0           mf_embedding_user[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 8)            0           mf_embedding_movie[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "layer2 (Dense)                  (None, 16)           528         layer1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "merge_1 (Merge)                 (None, 8)            0           flatten_3[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer3 (Dense)                  (None, 8)            136         layer2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "merge_3 (Merge)                 (None, 16)           0           merge_1[0][0]                    \n",
      "                                                                 layer3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Dense)              (None, 1)            17          merge_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 392,321\n",
      "Trainable params: 392,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 72002 samples, validate on 8001 samples\n",
      "Epoch 1/1\n",
      " - 15s - loss: -3.8657e+01 - val_loss: -4.0298e+01\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([train.userId, train.movieId], train.rating, epochs=1, verbose=2, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5652217389130545\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(test.rating, model.predict([test.userId, test.movieId])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the model heavily overfitted in the train data set. This can be overcome by adding a L2 or L1 regularizer or training on bigger data set. May be I will try this out a later stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Neural Collaborative Filtering](https://arxiv.org/abs/1708.05031)\n",
    "* [Xavier Amatriain Lecture](https://www.youtube.com/watch?v=bLhq63ygoU8)\n",
    "* [Fast ai lectures](http://course.fast.ai/lessons/lesson5.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
